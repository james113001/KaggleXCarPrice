{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8615951,"sourceType":"datasetVersion","datasetId":5156865}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport cudf\nfrom category_encoders import TargetEncoder\n\nfrom sklearn.model_selection import train_test_split\n# from sklearn.model_selection import KFold\n\nfrom cuml.ensemble import RandomForestRegressor \n# from sklearn.metrics import mean_squared_error, r2_score\n# from sklearn.preprocessing import OneHotEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T12:09:08.847644Z","iopub.execute_input":"2024-06-29T12:09:08.848199Z","iopub.status.idle":"2024-06-29T12:09:17.360764Z","shell.execute_reply.started":"2024-06-29T12:09:08.848171Z","shell.execute_reply":"2024-06-29T12:09:17.360035Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def cleandata(df):\n    # Apply the categorization function to the transmission column\n    df['Transmission_Category'] = df['transmission'].apply(categorize_transmission)\n    #idea for future: include speed\n\n    # Apply the parsing function to the engine column\n    df[['HP', 'Volume', 'Cylinders', 'Cylinder_Type','Turbo']] = df['engine'].apply(parse_engine).apply(pd.Series)\n    #idea: include\n    \n    \n    # Apply the function to fill missing HP values\n    df = fill_missing_hp(df)\n    df = fill_missing_val(df, 'Volume')\n    df = fill_missing_val(df, 'Cylinders')\n    df = fill_missing_val(df, 'Cylinder_Type')\n\n\n    df['HP'] = pd.to_numeric(df['HP'], errors='coerce')\n\n    # Correct the fuel type for Tesla\n    df['fuel_type'] = df.apply(correct_fuel_type, axis=1)\n    \n    cleanerdf = df.drop(columns=['id', 'engine', 'transmission'], inplace=False)\n    df_cleaned = cleanerdf.dropna()\n\n    # Apply the mapping to the columns\n    df_cleaned.loc[:,'int_col'] = df_cleaned['int_col'].apply(group_colors)\n    df_cleaned.loc[:,'ext_col'] = df_cleaned['ext_col'].apply(group_colors)\n    if 'not supported' in df_cleaned['fuel_type']:\n        df_cleaned.loc[df_cleaned['fuel_type']=='not supported', 'fuel_type'] = 'Gasoline'\n    df_cleaned = df_cleaned[df_cleaned['fuel_type'] != '–']\n    df_cleaned = df_cleaned[df_cleaned['int_col'] != '–']\n    df_cleaned = df_cleaned[df_cleaned['ext_col'] != '–']\n#     df_cleaned = df_cleaned[df_cleaned['price'] <= 2000000]\n    df_cleaned = df_cleaned[df_cleaned['milage'] <= 200000]\n    return df_cleaned\n\n\ndef group_colors(color):\n    color = color.lower()\n    color_groups = {\n        'black': ['black', 'jet', 'charcoal'],\n        'white': ['white', 'pearl', 'ivory'],\n        'red': ['red', 'maroon', 'burgundy'],\n        'blue': ['blue', 'navy', 'azure', 'cyan'],\n        'green': ['green', 'olive', 'lime'],\n        'yellow': ['yellow', 'gold', 'beige', 'sand'],\n        'grey': ['grey', 'gray', 'silver', 'metallic'],\n        'brown': ['brown', 'tan', 'chocolate'],\n        'other': []\n    }\n    \n    for main_color, sub_colors in color_groups.items():\n        if any(sub_color in color for sub_color in sub_colors):\n            return main_color\n    return 'other'\n\ndef fill_missing_hp(df):\n    df['HP'] = df.groupby(['model', 'brand', 'model_year'])['HP'].transform(\n        lambda x: x.fillna(x.mean())\n    )\n    \n    def get_closest_year_hp(row, df):\n        model, brand, year = row['model'], row['brand'], row['model_year']\n        mask = (df['model'] == model) & (df['brand'] == brand)\n        available_years = df[mask & df['HP'].notna()]['model_year'].unique()\n        \n        if available_years.size == 0:\n            return df['HP'].mode()[0]  # Use mode of all HPs if no match is found\n        \n        closest_year = available_years[np.abs(available_years - year).argmin()]\n        closest_year_hp = df[mask & (df['model_year'] == closest_year)]['HP'].mean()\n        \n        return closest_year_hp\n    \n    df['HP'] = df.apply(\n        lambda row: get_closest_year_hp(row, df) if pd.isnull(row['HP']) else row['HP'], axis=1\n    )\n    \n    return df\n\ndef fill_missing_val(df, col):\n    \n    df[col] = df.groupby(['model', 'brand', 'model_year'])[col].transform(\n        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n    )\n    \n    def get_closest_year_val(row, df, col):\n        model, brand, year = row['model'], row['brand'], row['model_year']\n        mask = (df['model'] == model) & (df['brand'] == brand)\n        available_years = df[mask & df[col].notna()]['model_year'].unique()\n        \n        if available_years.size == 0:\n            return df[col].mode()[0]  # Use mode of all HPs if no match is found\n        \n        closest_year = available_years[np.abs(available_years - year).argmin()]\n        closest_year_val = df[mask & (df['model_year'] == closest_year)][col].mode()\n        if closest_year_val.empty:\n            return df[col].mode()[0]\n        \n        return closest_year_val[0]\n    \n    df[col] = df.apply(\n        lambda row: get_closest_year_val(row, df, col) if pd.isnull(row[col]) else row[col], axis=1\n    )\n    \n    return df\n\ndef preprocess_categorical(df, columns):\n    for col in columns:\n        df[col] = df[col].fillna('Missing').astype(str)\n    return df\n\ndef group_rare_categories(series, threshold):\n    counts = series.value_counts()\n    rare = counts[counts < threshold].index\n    return series.apply(lambda x: 'Other' if x in rare else x)\n\n# Function to parse engine details\ndef parse_engine(engine_str):\n    # Regular expressions for extracting the details\n    hp_pattern = r'(\\d+\\.?\\d*)HP'\n    volume_pattern = r'(\\d+\\.?\\d*)L'\n    cylinders_acronym_pattern = r'(V|I|H)(\\d+)'\n    type_pattern = r'(V|Straight|I|H)?\\s*(\\d+)\\s*Cylinders?'\n\n    # Extracting the horsepower\n    hp = re.search(hp_pattern, engine_str)\n    hp = float(hp.group(1)) if hp else None\n    \n    if 'electric motor' in engine_str.lower() or 'electric fuel' in engine_str.lower():\n        return hp, 'Electric', 'Electric', 'Electric', 0\n    \n    \n    # Extracting the volume\n    volume = re.search(volume_pattern, engine_str)\n    volume = str(volume.group(1)) if volume else None\n    \n\n    # Extracting the number and type of cylinders\n    cylinders_match = re.search(cylinders_acronym_pattern, engine_str)\n    if cylinders_match:\n        cylinder_type = 'V' if cylinders_match.group(1) == 'V' else 'Inline'\n        cylinders = int(cylinders_match.group(2))\n        if cylinders_match.group(1) == 'H':\n                cylinder_type = 'Straight'\n    else:\n        cylinders_match = re.search(type_pattern, engine_str)\n        if cylinders_match:\n            cylinder_type = cylinders_match.group(1) if cylinders_match.group(1) else ''\n            cylinders = str(cylinders_match.group(2))\n            cylinder_type = cylinder_type or ('V' if 'V' in engine_str else 'Straight' if 'Straight' in engine_str else 'Inline')\n        else:\n            cylinders = None\n            cylinder_type = None\n\n    turbo = 'Y' if 'Turbo' in engine_str or 'turbo' in engine_str else 'N'\n\n    return hp, volume, cylinders, cylinder_type, turbo\n\n# Function to correct fuel type for Tesla\ndef correct_fuel_type(row):\n    if 'Tesla' in row['brand'] or 'electric motor' in row['engine'].lower():\n        return 'Electric'\n    return row['fuel_type']\n\n# Function to categorize transmission\ndef categorize_transmission(transmission_str):\n    transmission_str = transmission_str.lower()\n    if 'manual' in transmission_str or 'm/t' in transmission_str:\n        return 'Manual'\n    elif 'dual' in transmission_str or 'dual shift' in transmission_str:\n        return 'Dual Shift'\n    elif 'cvt' in transmission_str:\n        return 'CVT'\n    else:\n        return 'Auto'","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:09:19.365212Z","iopub.execute_input":"2024-06-29T12:09:19.365809Z","iopub.status.idle":"2024-06-29T12:09:19.398452Z","shell.execute_reply.started":"2024-06-29T12:09:19.365765Z","shell.execute_reply":"2024-06-29T12:09:19.397709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/kagglex-skill-assessment-challenge/train.csv')\ndf.describe()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:09:23.674394Z","iopub.execute_input":"2024-06-29T12:09:23.675087Z","iopub.status.idle":"2024-06-29T12:09:23.973721Z","shell.execute_reply.started":"2024-06-29T12:09:23.675055Z","shell.execute_reply":"2024-06-29T12:09:23.972851Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id    brand          model  model_year  milage fuel_type  \\\n0   0     Ford   F-150 Lariat        2018   74349  Gasoline   \n1   1      BMW          335 i        2007   80000  Gasoline   \n2   2   Jaguar      XF Luxury        2009   91491  Gasoline   \n3   3      BMW   X7 xDrive40i        2022    2437    Hybrid   \n4   4  Pontiac  Firebird Base        2001  111000  Gasoline   \n\n                                              engine  \\\n0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   \n3  335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n4      200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel   \n\n                     transmission ext_col int_col       accident clean_title  \\\n0                    10-Speed A/T    Blue    Gray  None reported         Yes   \n1                     6-Speed M/T   Black   Black  None reported         Yes   \n2                     6-Speed A/T  Purple   Beige  None reported         Yes   \n3  Transmission w/Dual Shift Mode    Gray   Brown  None reported         Yes   \n4                             A/T   White   Black  None reported         Yes   \n\n   price  \n0  11000  \n1   8250  \n2  15000  \n3  63500  \n4   7850  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>brand</th>\n      <th>model</th>\n      <th>model_year</th>\n      <th>milage</th>\n      <th>fuel_type</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>ext_col</th>\n      <th>int_col</th>\n      <th>accident</th>\n      <th>clean_title</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Ford</td>\n      <td>F-150 Lariat</td>\n      <td>2018</td>\n      <td>74349</td>\n      <td>Gasoline</td>\n      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n      <td>10-Speed A/T</td>\n      <td>Blue</td>\n      <td>Gray</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>11000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>BMW</td>\n      <td>335 i</td>\n      <td>2007</td>\n      <td>80000</td>\n      <td>Gasoline</td>\n      <td>300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n      <td>6-Speed M/T</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>8250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Jaguar</td>\n      <td>XF Luxury</td>\n      <td>2009</td>\n      <td>91491</td>\n      <td>Gasoline</td>\n      <td>300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel</td>\n      <td>6-Speed A/T</td>\n      <td>Purple</td>\n      <td>Beige</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>15000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>BMW</td>\n      <td>X7 xDrive40i</td>\n      <td>2022</td>\n      <td>2437</td>\n      <td>Hybrid</td>\n      <td>335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n      <td>Transmission w/Dual Shift Mode</td>\n      <td>Gray</td>\n      <td>Brown</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>63500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Pontiac</td>\n      <td>Firebird Base</td>\n      <td>2001</td>\n      <td>111000</td>\n      <td>Gasoline</td>\n      <td>200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel</td>\n      <td>A/T</td>\n      <td>White</td>\n      <td>Black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>7850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate the percentage of missing values in each column\n# missing_percentage = df.isnull().mean() * 100\n\n# # Display the percentage of missing values\n# print(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T01:32:45.060271Z","iopub.execute_input":"2024-06-21T01:32:45.060663Z","iopub.status.idle":"2024-06-21T01:32:45.107817Z","shell.execute_reply.started":"2024-06-21T01:32:45.060632Z","shell.execute_reply":"2024-06-21T01:32:45.106425Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"id                       0.000000\nbrand                    0.000000\nmodel                    0.000000\nmodel_year               0.000000\nmilage                   0.000000\nfuel_type                0.000000\nengine                   0.000000\ntransmission             0.000000\next_col                  0.000000\nint_col                  0.000000\naccident                 0.000000\nclean_title              0.000000\nprice                    0.000000\nTransmission_Category    0.000000\nHP                       7.475172\nVolume                   0.794133\nCylinders                0.884418\nCylinder_Type            0.884418\nTurbo                    0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"categorical_cols = ['brand', 'model', 'fuel_type', 'ext_col', 'int_col', 'accident', 'clean_title', 'Volume','Cylinders','Cylinder_Type', 'Transmission_Category', 'Turbo']\n\ncleaner_df = cleandata(df)\ndf_cleaned = cleaner_df[cleaner_df['price']<= 2000000]\ndf_cleaned.loc[:,'model'] = group_rare_categories(df_cleaned['model'], threshold=2)\ndf_cleaned.loc[:,'brand'] = group_rare_categories(df_cleaned['brand'], threshold=10)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:09:25.945984Z","iopub.execute_input":"2024-06-29T12:09:25.946316Z","iopub.status.idle":"2024-06-29T12:10:47.437082Z","shell.execute_reply.started":"2024-06-29T12:09:25.946291Z","shell.execute_reply":"2024-06-29T12:10:47.435874Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4168761369.py:85: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/4168761369.py:85: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/4168761369.py:85: UserWarning: Unable to sort modes: '<' not supported between instances of 'int' and 'str'\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/4168761369.py:85: UserWarning: Unable to sort modes: '<' not supported between instances of 'str' and 'int'\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/4168761369.py:97: UserWarning: Unable to sort modes: '<' not supported between instances of 'str' and 'int'\n  closest_year_val = df[mask & (df['model_year'] == closest_year)][col].mode()\n/tmp/ipykernel_34/4168761369.py:85: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the percentage of missing values in each column\nmissing_percentage = df_cleaned.isnull().mean() * 100\n\n# Display the percentage of missing values\nprint(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:12:30.602632Z","iopub.execute_input":"2024-06-29T12:12:30.603296Z","iopub.status.idle":"2024-06-29T12:12:30.671146Z","shell.execute_reply.started":"2024-06-29T12:12:30.603263Z","shell.execute_reply":"2024-06-29T12:12:30.670242Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"brand                    0.0\nmodel                    0.0\nmodel_year               0.0\nmilage                   0.0\nfuel_type                0.0\next_col                  0.0\nint_col                  0.0\naccident                 0.0\nclean_title              0.0\nprice                    0.0\nTransmission_Category    0.0\nHP                       0.0\nVolume                   0.0\nCylinders                0.0\nCylinder_Type            0.0\nTurbo                    0.0\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX = df_cleaned.drop('price', axis=1)\nX = X.drop(columns=['int_col'])##########################\n\ny = df_cleaned['price']\n\nencoder = TargetEncoder()\nX_encoded = encoder.fit_transform(X, y)\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(X_encoded, y, test_size=0.1, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2222, random_state=42)  # 0.2222 * 0.9 = 0.2\n\n# Convert to cuDF\nX_train_cudf = cudf.DataFrame.from_pandas(X_train)\nX_val_cudf = cudf.DataFrame.from_pandas(X_val)\nX_test_cudf = cudf.DataFrame.from_pandas(X_test)\ny_train_cudf = cudf.Series(y_train.values)\ny_val_cudf = cudf.Series(y_val.values)\ny_test_cudf = cudf.Series(y_test.values)\n\n\n# Train the Random Forest model\nfinal_model = RandomForestRegressor(n_estimators=30, max_depth=5, random_state=42)\nfinal_model.fit(X_train_cudf, y_train_cudf)\n\n# Evaluate on the validation set\nval_predictions = final_model.predict(X_val_cudf)\nval_score = final_model.score(X_val_cudf, y_val_cudf)\nprint(f\"Validation Score: {val_score}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-29T12:12:32.571294Z","iopub.execute_input":"2024-06-29T12:12:32.571864Z","iopub.status.idle":"2024-06-29T12:12:34.803020Z","shell.execute_reply.started":"2024-06-29T12:12:32.571833Z","shell.execute_reply":"2024-06-29T12:12:34.802112Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:344: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n  return func(**kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Validation Score: 0.2035170472719463\n","output_type":"stream"}]},{"cell_type":"code","source":"# Finding optimal num trees and depth------------------------------------------------------\n\nfrom sklearn.model_selection import GridSearchCV\nfrom cuml.ensemble import RandomForestRegressor as cuRF\nimport cudf\nimport numpy as np\n\nclass cuMLWrapper:\n    def __init__(self, **params):\n        self.model = cuRF(**params)\n\n    def fit(self, X, y):\n        self.model.fit(cudf.DataFrame.from_pandas(X), cudf.Series(y))\n        return self\n\n    def predict(self, X):\n        return self.model.predict(cudf.DataFrame.from_pandas(X)).get()\n\n    def score(self, X, y):\n        return self.model.score(cudf.DataFrame.from_pandas(X), cudf.Series(y))\n\n    def get_params(self, deep=True):\n        return self.model.get_params(deep)\n\n    def set_params(self, **params):\n        self.model.set_params(**params)\n        return self\n\n# Define the parameter grid for Grid Search\nparam_grid = {\n    'n_estimators': [10, 50, 100, 150, 200],  # Example values, adjust as needed\n    'max_depth': [5, 10, 15, 20]  # Example values, adjust as needed\n}\n\n# Convert data to cuDF\nX_train_full_cudf = cudf.DataFrame.from_pandas(X_train_full)\ny_train_full_cudf = cudf.Series(y_train_full.values)\n\n# Initialize the model\nrf_model = cuMLWrapper()\n\n# Perform Grid Search\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1)\ngrid_search.fit(X_train_full, y_train_full)\n\n# Get the best parameters\nbest_params = grid_search.best_params_\nprint(f\"Best parameters found: {best_params}\")\n\n# Train the final model with the best parameters\nbest_model = cuRF(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'])\nbest_model.fit(X_train_cudf, y_train_cudf)\n\n# Evaluate on the validation set with the best model\nval_predictions_best = best_model.predict(X_val_cudf)\nval_score_best = best_model.score(X_val_cudf, y_val_cudf)\nprint(f\"Validation Score with Best Model: {val_score_best}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:15:10.952037Z","iopub.execute_input":"2024-06-21T22:15:10.952651Z","iopub.status.idle":"2024-06-21T22:16:23.962895Z","shell.execute_reply.started":"2024-06-21T22:15:10.952619Z","shell.execute_reply":"2024-06-21T22:16:23.961862Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":148,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n  ret = func(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Best parameters found: {'max_depth': 5, 'n_estimators': 50}\nValidation Score with Best Model: 0.2031629092517635\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the test data\ntest_file_path = '/kaggle/input/kagglex-skill-assessment-challenge/test.csv'  # Replace with your actual file path\ntest_df = pd.read_csv(test_file_path)\ntest_ids = test_df['id']\n\n # Apply the categorization function to the transmission column\ntest_df['Transmission_Category'] = test_df['transmission'].apply(categorize_transmission)\n#idea for future: include speed\n\n# Apply the parsing function to the engine column\ntest_df[['HP', 'Volume', 'Cylinders', 'Cylinder_Type','Turbo']] = test_df['engine'].apply(parse_engine).apply(pd.Series)\n#idea: include\n\ntest_df = fill_missing_hp(test_df)\ntest_df = fill_missing_val(test_df, 'Volume')\ntest_df = fill_missing_val(test_df, 'Cylinders')\ntest_df = fill_missing_val(test_df, 'Cylinder_Type')\n\ntest_df['HP'] = pd.to_numeric(test_df['HP'], errors='coerce')\n\n# Correct the fuel type for Tesla\ntest_df['fuel_type'] = test_df.apply(correct_fuel_type, axis=1)\n\nif 'not supported' in test_df['fuel_type']:\n    test_df.loc[test_df['fuel_type']=='not supported', 'fuel_type'] = 'Gasoline'\n    \n# Apply the mapping to the columns\ntest_df.loc[:,'int_col'] = test_df['int_col'].apply(group_colors)\ntest_df.loc[:,'ext_col'] = test_df['ext_col'].apply(group_colors)\n\ndf_cleaned_test = test_df.drop(columns=['id', 'engine', 'transmission' , 'int_col'], inplace=False)\n\ndf_cleaned_test.loc[:,'model'] = group_rare_categories(df_cleaned_test['model'], threshold=2)\ndf_cleaned_test.loc[:,'brand'] = group_rare_categories(df_cleaned_test['brand'], threshold=10)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:17:19.774552Z","iopub.execute_input":"2024-06-21T22:17:19.775269Z","iopub.status.idle":"2024-06-21T22:18:12.740574Z","shell.execute_reply.started":"2024-06-21T22:17:19.775234Z","shell.execute_reply":"2024-06-21T22:18:12.739538Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2297922468.py:87: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/2297922468.py:87: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/2297922468.py:87: UserWarning: Unable to sort modes: '<' not supported between instances of 'str' and 'int'\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/2297922468.py:87: UserWarning: Unable to sort modes: '<' not supported between instances of 'int' and 'str'\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n/tmp/ipykernel_34/2297922468.py:87: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_cleaned['int_col'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:02:41.008332Z","iopub.execute_input":"2024-06-21T22:02:41.009030Z","iopub.status.idle":"2024-06-21T22:02:41.023202Z","shell.execute_reply.started":"2024-06-21T22:02:41.009000Z","shell.execute_reply":"2024-06-21T22:02:41.022339Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"int_col\nblack     32064\nyellow     7864\ngrey       6045\nbrown      2271\nother      1873\nred        1536\nwhite      1188\nblue        226\ngreen        53\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_df[test_df.isnull().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:21:48.226897Z","iopub.execute_input":"2024-06-21T20:21:48.227252Z","iopub.status.idle":"2024-06-21T20:21:48.302178Z","shell.execute_reply.started":"2024-06-21T20:21:48.227225Z","shell.execute_reply":"2024-06-21T20:21:48.301194Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"          id        brand                         model  model_year  milage  \\\n16     54289       Toyota                    Tundra SR5        2023    2925   \n89     54362       Toyota             Land Cruiser Base        2023    7900   \n108    54381  Rolls-Royce                      Cullinan        2022    7928   \n115    54388         Ford                      F-150 XL        2023    2823   \n161    54434        Mazda           CX-9 Carbon Edition        2021   36844   \n...      ...          ...                           ...         ...     ...   \n35960  90233        Mazda          Mazda3 Grand Touring        2019   70891   \n36010  90283         Ford            F-150 XLT SuperCab        1993  195000   \n36081  90354      Bentley  Bentayga Azure First Edition        2023    1335   \n36115  90388    Chevrolet                  Colorado Z71        2019   71536   \n36163  90436    Chevrolet         Traverse High Country        2020   61830   \n\n      fuel_type                            engine        transmission ext_col  \\\n16     Gasoline   3.4L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic    grey   \n89            –                                 –        10-Speed A/T   green   \n108    Gasoline  6.7L V12 48V GDI DOHC Twin Turbo   8-Speed Automatic   other   \n115    Gasoline   3.5L V6 24V PDI DOHC Twin Turbo           Automatic   black   \n161    Gasoline        2.5L I4 16V GDI DOHC Turbo   8-Speed Automatic    grey   \n...         ...                               ...                 ...     ...   \n35960  Gasoline              2.5L I4 16V GDI DOHC   6-Speed Automatic   white   \n36010         –                                 –                 A/T    blue   \n36081  Gasoline   4.0L V8 32V GDI DOHC Twin Turbo   8-Speed Automatic   black   \n36115  Gasoline              3.6L V6 24V GDI DOHC           Automatic   black   \n36163  Gasoline              3.6L V6 24V GDI DOHC   8-Speed Automatic     red   \n\n      int_col       accident clean_title Transmission_Category  HP Volume  \\\n16      black  None reported         Yes                  Auto NaN    3.4   \n89      white  None reported         Yes                  Auto NaN   None   \n108     white  None reported         Yes                  Auto NaN    6.7   \n115     black  None reported         Yes                  Auto NaN    3.5   \n161    yellow  None reported         Yes                  Auto NaN    2.5   \n...       ...            ...         ...                   ...  ..    ...   \n35960   other  None reported         Yes                  Auto NaN    2.5   \n36010    grey  None reported         Yes                  Auto NaN   None   \n36081   other  None reported         Yes                  Auto NaN    4.0   \n36115   black  None reported         Yes                  Auto NaN    3.6   \n36163   black  None reported         Yes                  Auto NaN    3.6   \n\n      Cylinders Cylinder_Type Turbo  \n16            6             V     Y  \n89         None          None     N  \n108          12             V     Y  \n115           6             V     Y  \n161           4        Inline     Y  \n...         ...           ...   ...  \n35960         4        Inline     N  \n36010      None          None     N  \n36081         8             V     Y  \n36115         6             V     N  \n36163         6             V     N  \n\n[1157 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>brand</th>\n      <th>model</th>\n      <th>model_year</th>\n      <th>milage</th>\n      <th>fuel_type</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>ext_col</th>\n      <th>int_col</th>\n      <th>accident</th>\n      <th>clean_title</th>\n      <th>Transmission_Category</th>\n      <th>HP</th>\n      <th>Volume</th>\n      <th>Cylinders</th>\n      <th>Cylinder_Type</th>\n      <th>Turbo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>54289</td>\n      <td>Toyota</td>\n      <td>Tundra SR5</td>\n      <td>2023</td>\n      <td>2925</td>\n      <td>Gasoline</td>\n      <td>3.4L V6 24V PDI DOHC Twin Turbo</td>\n      <td>10-Speed Automatic</td>\n      <td>grey</td>\n      <td>black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>3.4</td>\n      <td>6</td>\n      <td>V</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>54362</td>\n      <td>Toyota</td>\n      <td>Land Cruiser Base</td>\n      <td>2023</td>\n      <td>7900</td>\n      <td>–</td>\n      <td>–</td>\n      <td>10-Speed A/T</td>\n      <td>green</td>\n      <td>white</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>54381</td>\n      <td>Rolls-Royce</td>\n      <td>Cullinan</td>\n      <td>2022</td>\n      <td>7928</td>\n      <td>Gasoline</td>\n      <td>6.7L V12 48V GDI DOHC Twin Turbo</td>\n      <td>8-Speed Automatic</td>\n      <td>other</td>\n      <td>white</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>6.7</td>\n      <td>12</td>\n      <td>V</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>54388</td>\n      <td>Ford</td>\n      <td>F-150 XL</td>\n      <td>2023</td>\n      <td>2823</td>\n      <td>Gasoline</td>\n      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n      <td>Automatic</td>\n      <td>black</td>\n      <td>black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>3.5</td>\n      <td>6</td>\n      <td>V</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>54434</td>\n      <td>Mazda</td>\n      <td>CX-9 Carbon Edition</td>\n      <td>2021</td>\n      <td>36844</td>\n      <td>Gasoline</td>\n      <td>2.5L I4 16V GDI DOHC Turbo</td>\n      <td>8-Speed Automatic</td>\n      <td>grey</td>\n      <td>yellow</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>2.5</td>\n      <td>4</td>\n      <td>Inline</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35960</th>\n      <td>90233</td>\n      <td>Mazda</td>\n      <td>Mazda3 Grand Touring</td>\n      <td>2019</td>\n      <td>70891</td>\n      <td>Gasoline</td>\n      <td>2.5L I4 16V GDI DOHC</td>\n      <td>6-Speed Automatic</td>\n      <td>white</td>\n      <td>other</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>2.5</td>\n      <td>4</td>\n      <td>Inline</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>36010</th>\n      <td>90283</td>\n      <td>Ford</td>\n      <td>F-150 XLT SuperCab</td>\n      <td>1993</td>\n      <td>195000</td>\n      <td>–</td>\n      <td>–</td>\n      <td>A/T</td>\n      <td>blue</td>\n      <td>grey</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>36081</th>\n      <td>90354</td>\n      <td>Bentley</td>\n      <td>Bentayga Azure First Edition</td>\n      <td>2023</td>\n      <td>1335</td>\n      <td>Gasoline</td>\n      <td>4.0L V8 32V GDI DOHC Twin Turbo</td>\n      <td>8-Speed Automatic</td>\n      <td>black</td>\n      <td>other</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>8</td>\n      <td>V</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>36115</th>\n      <td>90388</td>\n      <td>Chevrolet</td>\n      <td>Colorado Z71</td>\n      <td>2019</td>\n      <td>71536</td>\n      <td>Gasoline</td>\n      <td>3.6L V6 24V GDI DOHC</td>\n      <td>Automatic</td>\n      <td>black</td>\n      <td>black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>3.6</td>\n      <td>6</td>\n      <td>V</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>36163</th>\n      <td>90436</td>\n      <td>Chevrolet</td>\n      <td>Traverse High Country</td>\n      <td>2020</td>\n      <td>61830</td>\n      <td>Gasoline</td>\n      <td>3.6L V6 24V GDI DOHC</td>\n      <td>8-Speed Automatic</td>\n      <td>red</td>\n      <td>black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>Auto</td>\n      <td>NaN</td>\n      <td>3.6</td>\n      <td>6</td>\n      <td>V</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>1157 rows × 18 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate the percentage of missing values in each column\n# missing_percentage = df_cleaned.isnull().mean() * 100\n\n# # Display the percentage of missing values\n# print(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T21:09:52.078317Z","iopub.execute_input":"2024-06-21T21:09:52.078764Z","iopub.status.idle":"2024-06-21T21:09:52.127287Z","shell.execute_reply.started":"2024-06-21T21:09:52.078732Z","shell.execute_reply":"2024-06-21T21:09:52.126292Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"brand                    0.0\nmodel                    0.0\nmodel_year               0.0\nmilage                   0.0\nfuel_type                0.0\next_col                  0.0\nint_col                  0.0\naccident                 0.0\nclean_title              0.0\nTransmission_Category    0.0\nHP                       0.0\nVolume                   0.0\nCylinders                0.0\nCylinder_Type            0.0\nTurbo                    0.0\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Encode categorical variables in the test set using the already fitted encoder\nX_test_encoded = encoder.transform(df_cleaned_test)\n\n# Convert the encoded test set to cuDF\nX_test_encoded_cudf = cudf.DataFrame.from_pandas(X_test_encoded)\n\n# Predict on the test set using the final model\ntest_predictions = final_model.predict(X_test_encoded_cudf)\n\n# print(test_predictions)\n# Create a DataFrame with original ID and prediction\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'price': test_predictions.to_numpy() # Convert cuDF Series to numpy array\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('random_forest_submission_nointcol30.csv', index=False)\n\nprint(submission_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:23:02.230457Z","iopub.execute_input":"2024-06-21T22:23:02.230852Z","iopub.status.idle":"2024-06-21T22:23:02.474438Z","shell.execute_reply.started":"2024-06-21T22:23:02.230803Z","shell.execute_reply":"2024-06-21T22:23:02.473429Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stdout","text":"      id         price\n0  54273  22182.981172\n1  54274  21856.438365\n2  54275  24834.897483\n3  54276  53706.708440\n4  54277  43369.470904\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport statsmodels.api as sm\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Assuming X_encoded is the DataFrame with your features after encoding\n# Add a constant term for the intercept in the regression model\nX_with_const = sm.add_constant(X_encoded)\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X_with_const.columns\nvif_data['VIF'] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n\n# Display the VIF data\nprint(vif_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:09:32.626134Z","iopub.execute_input":"2024-06-21T22:09:32.626483Z","iopub.status.idle":"2024-06-21T22:09:34.143215Z","shell.execute_reply.started":"2024-06-21T22:09:32.626457Z","shell.execute_reply":"2024-06-21T22:09:34.141876Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"                  feature            VIF\n0                   brand       1.474554\n1                   model       2.394886\n2              model_year       1.939063\n3                  milage       1.940299\n4               fuel_type       1.085322\n5                 ext_col       1.024866\n6                 int_col       1.127283\n7                accident       1.113962\n8             clean_title  271073.077235\n9   Transmission_Category       1.064012\n10                     HP       2.841948\n11                 Volume       1.928271\n12              Cylinders       1.836618\n13          Cylinder_Type       1.090324\n14                  Turbo       1.092463\n","output_type":"stream"}]}]}